{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6271e32f",
   "metadata": {},
   "source": [
    "### Preprocesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e581c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import libraries for plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0cacc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the cleared data frame from feature selection\n",
    "df = pd.read_csv('free_pokemon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fb5180f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>Total</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>117</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>440</td>\n",
       "      <td>55</td>\n",
       "      <td>65</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>45</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>119</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>450</td>\n",
       "      <td>80</td>\n",
       "      <td>92</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>80</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>124</td>\n",
       "      <td>14</td>\n",
       "      <td>8.0</td>\n",
       "      <td>455</td>\n",
       "      <td>65</td>\n",
       "      <td>50</td>\n",
       "      <td>35</td>\n",
       "      <td>115</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>125</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>490</td>\n",
       "      <td>65</td>\n",
       "      <td>83</td>\n",
       "      <td>57</td>\n",
       "      <td>95</td>\n",
       "      <td>85</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>126</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>495</td>\n",
       "      <td>65</td>\n",
       "      <td>95</td>\n",
       "      <td>57</td>\n",
       "      <td>100</td>\n",
       "      <td>85</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     #  Type 1  Type 2  Total  HP  Attack  Defense  Sp. Atk  Sp. Def  Speed  \\\n",
       "0  117       3     0.0    440  55      65       95       95       45     85   \n",
       "1  119       3     0.0    450  80      92       65       65       80     68   \n",
       "2  124      14     8.0    455  65      50       35      115       95     95   \n",
       "3  125       7     0.0    490  65      83       57       95       85    105   \n",
       "4  126       2     0.0    495  65      95       57      100       85     93   \n",
       "\n",
       "   Generation  Legendary  \n",
       "0           1          0  \n",
       "1           1          0  \n",
       "2           1          0  \n",
       "3           1          0  \n",
       "4           1          0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aed9d1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 360 entries, 0 to 359\n",
      "Data columns (total 12 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   #           360 non-null    int64  \n",
      " 1   Type 1      360 non-null    int64  \n",
      " 2   Type 2      360 non-null    float64\n",
      " 3   Total       360 non-null    int64  \n",
      " 4   HP          360 non-null    int64  \n",
      " 5   Attack      360 non-null    int64  \n",
      " 6   Defense     360 non-null    int64  \n",
      " 7   Sp. Atk     360 non-null    int64  \n",
      " 8   Sp. Def     360 non-null    int64  \n",
      " 9   Speed       360 non-null    int64  \n",
      " 10  Generation  360 non-null    int64  \n",
      " 11  Legendary   360 non-null    int64  \n",
      "dtypes: float64(1), int64(11)\n",
      "memory usage: 33.9 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fba7124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check for missing values\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Calculate the number of missing values in each column\n",
    "missing = df.isnull().sum()\n",
    "\n",
    "# Plot the number of missing values in each column\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(x=missing.index, y=missing.values)\n",
    "\n",
    "# Add labels and title to the plot\n",
    "plt.xlabel(\"Columns\")\n",
    "plt.ylabel(\"Number of Missing Values\")\n",
    "plt.title(\"Number of Missing Values in Each Column\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d13449",
   "metadata": {},
   "source": [
    "### Classical Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c7733f",
   "metadata": {},
   "source": [
    "__Undersampling__\n",
    "\n",
    "is the most straightforward technique to balance an unbalanced data set. The idea is to reduce the number of samples in the majority class to the number equal to the number of samples in the minority class. Usually, it is done by randomly selecting m samples from the majority class, where m is the number of samples in the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e28715e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Collecting imbalanced-learn\n",
      "  Using cached imbalanced_learn-0.10.1-py3-none-any.whl (226 kB)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\python310\\lib\\site-packages (from imbalanced-learn->imblearn) (1.9.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\python310\\lib\\site-packages (from imbalanced-learn->imblearn) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\python310\\lib\\site-packages (from imbalanced-learn->imblearn) (1.23.5)\n",
      "Collecting joblib>=1.1.1\n",
      "  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\python310\\lib\\site-packages (from imbalanced-learn->imblearn) (1.1.3)\n",
      "Installing collected packages: joblib, imbalanced-learn, imblearn\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.1.0\n",
      "    Uninstalling joblib-1.1.0:\n",
      "      Successfully uninstalled joblib-1.1.0\n",
      "Successfully installed imbalanced-learn-0.10.1 imblearn-0.0 joblib-1.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3fa8dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>Total</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>117</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>440</td>\n",
       "      <td>55</td>\n",
       "      <td>65</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>45</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>119</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>450</td>\n",
       "      <td>80</td>\n",
       "      <td>92</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>80</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>124</td>\n",
       "      <td>14</td>\n",
       "      <td>8.0</td>\n",
       "      <td>455</td>\n",
       "      <td>65</td>\n",
       "      <td>50</td>\n",
       "      <td>35</td>\n",
       "      <td>115</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>125</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>490</td>\n",
       "      <td>65</td>\n",
       "      <td>83</td>\n",
       "      <td>57</td>\n",
       "      <td>95</td>\n",
       "      <td>85</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>126</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>495</td>\n",
       "      <td>65</td>\n",
       "      <td>95</td>\n",
       "      <td>57</td>\n",
       "      <td>100</td>\n",
       "      <td>85</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>591</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>464</td>\n",
       "      <td>114</td>\n",
       "      <td>85</td>\n",
       "      <td>70</td>\n",
       "      <td>85</td>\n",
       "      <td>80</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>593</td>\n",
       "      <td>3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>480</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "      <td>85</td>\n",
       "      <td>105</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>596</td>\n",
       "      <td>4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>472</td>\n",
       "      <td>70</td>\n",
       "      <td>77</td>\n",
       "      <td>60</td>\n",
       "      <td>97</td>\n",
       "      <td>60</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>600</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>440</td>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "      <td>95</td>\n",
       "      <td>70</td>\n",
       "      <td>85</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>603</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>405</td>\n",
       "      <td>65</td>\n",
       "      <td>85</td>\n",
       "      <td>70</td>\n",
       "      <td>75</td>\n",
       "      <td>70</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       #  Type 1  Type 2  Total   HP  Attack  Defense  Sp. Atk  Sp. Def  \\\n",
       "0    117       3     0.0    440   55      65       95       95       45   \n",
       "1    119       3     0.0    450   80      92       65       65       80   \n",
       "2    124      14     8.0    455   65      50       35      115       95   \n",
       "3    125       7     0.0    490   65      83       57       95       85   \n",
       "4    126       2     0.0    495   65      95       57      100       85   \n",
       "..   ...     ...     ...    ...  ...     ...      ...      ...      ...   \n",
       "355  591       1     1.0    464  114      85       70       85       80   \n",
       "356  593       3    16.0    480  100      60       70       85      105   \n",
       "357  596       4    14.0    472   70      77       60       97       60   \n",
       "358  600      17     0.0    440   60      80       95       70       85   \n",
       "359  603       7     0.0    405   65      85       70       75       70   \n",
       "\n",
       "     Speed  Generation  Legendary  \n",
       "0       85           1          0  \n",
       "1       68           1          0  \n",
       "2       95           1          0  \n",
       "3      105           1          0  \n",
       "4       93           1          0  \n",
       "..     ...         ...        ...  \n",
       "355     30           5          0  \n",
       "356     60           5          0  \n",
       "357    108           5          0  \n",
       "358     50           5          0  \n",
       "359     40           5          0  \n",
       "\n",
       "[360 rows x 12 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "296ac5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    1\n",
      "Name: Legendary, dtype: int64\n",
      "Confusion Matrix:\n",
      " [[70 38]\n",
      " [ 0  0]]\n",
      "Accuracy: 0.6481481481481481\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Assuming df is your DataFrame as given above\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('Legendary', axis=1)\n",
    "y = df['Legendary']\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "\n",
    "# Fit and resample the data using RandomUnderSampler\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# Combine the resampled feature with the rest of the dataset\n",
    "resampled_df = pd.concat([pd.DataFrame(X_resampled), pd.DataFrame(y_resampled, columns=[\"Legendary\"])], axis=1)\n",
    "\n",
    "# Check the distribution of the Legendary feature after undersampling\n",
    "print(resampled_df[\"Legendary\"].value_counts())\n",
    "\n",
    "# Create a logistic regression model\n",
    "model = LogisticRegression(max_iter=500)\n",
    "\n",
    "# Train the model on the resampled (balanced) training data\n",
    "model.fit(X_resampled, y_resampled)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Test the model on the testing data\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Calculate the accuracy score\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", acc_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "720c4d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>Total</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>222</td>\n",
       "      <td>3</td>\n",
       "      <td>11.0</td>\n",
       "      <td>380</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>85</td>\n",
       "      <td>65</td>\n",
       "      <td>85</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>481</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>580</td>\n",
       "      <td>80</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>80</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     #  Type 1  Type 2  Total  HP  Attack  Defense  Sp. Atk  Sp. Def  Speed  \\\n",
       "0  222       3    11.0    380  55      55       85       65       85     35   \n",
       "1  481      11     0.0    580  80     105      105      105      105     80   \n",
       "\n",
       "   Generation  Legendary  \n",
       "0           2          0  \n",
       "1           4          1  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resampled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4390c2d7",
   "metadata": {},
   "source": [
    "__Class Weights__\n",
    "\n",
    "In the examples above with the confusion matrix, we saw that sometimes for a model, it is more convenient to classify all samples as majority class samples. A way to escape this situation is to penalize harder errors by misclassifying minority class samples. In the base case, every error during classification is equal to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bb6bc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_weight = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0277546f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>Total</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>117</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>440</td>\n",
       "      <td>55</td>\n",
       "      <td>65</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>45</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>119</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>450</td>\n",
       "      <td>80</td>\n",
       "      <td>92</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>80</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>124</td>\n",
       "      <td>14</td>\n",
       "      <td>8.0</td>\n",
       "      <td>455</td>\n",
       "      <td>65</td>\n",
       "      <td>50</td>\n",
       "      <td>35</td>\n",
       "      <td>115</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>125</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>490</td>\n",
       "      <td>65</td>\n",
       "      <td>83</td>\n",
       "      <td>57</td>\n",
       "      <td>95</td>\n",
       "      <td>85</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>126</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>495</td>\n",
       "      <td>65</td>\n",
       "      <td>95</td>\n",
       "      <td>57</td>\n",
       "      <td>100</td>\n",
       "      <td>85</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>591</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>464</td>\n",
       "      <td>114</td>\n",
       "      <td>85</td>\n",
       "      <td>70</td>\n",
       "      <td>85</td>\n",
       "      <td>80</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>593</td>\n",
       "      <td>3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>480</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "      <td>85</td>\n",
       "      <td>105</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>596</td>\n",
       "      <td>4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>472</td>\n",
       "      <td>70</td>\n",
       "      <td>77</td>\n",
       "      <td>60</td>\n",
       "      <td>97</td>\n",
       "      <td>60</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>600</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>440</td>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "      <td>95</td>\n",
       "      <td>70</td>\n",
       "      <td>85</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>603</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>405</td>\n",
       "      <td>65</td>\n",
       "      <td>85</td>\n",
       "      <td>70</td>\n",
       "      <td>75</td>\n",
       "      <td>70</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       #  Type 1  Type 2  Total   HP  Attack  Defense  Sp. Atk  Sp. Def  \\\n",
       "0    117       3     0.0    440   55      65       95       95       45   \n",
       "1    119       3     0.0    450   80      92       65       65       80   \n",
       "2    124      14     8.0    455   65      50       35      115       95   \n",
       "3    125       7     0.0    490   65      83       57       95       85   \n",
       "4    126       2     0.0    495   65      95       57      100       85   \n",
       "..   ...     ...     ...    ...  ...     ...      ...      ...      ...   \n",
       "355  591       1     1.0    464  114      85       70       85       80   \n",
       "356  593       3    16.0    480  100      60       70       85      105   \n",
       "357  596       4    14.0    472   70      77       60       97       60   \n",
       "358  600      17     0.0    440   60      80       95       70       85   \n",
       "359  603       7     0.0    405   65      85       70       75       70   \n",
       "\n",
       "     Speed  Generation  Legendary  \n",
       "0       85           1          0  \n",
       "1       68           1          0  \n",
       "2       95           1          0  \n",
       "3      105           1          0  \n",
       "4       93           1          0  \n",
       "..     ...         ...        ...  \n",
       "355     30           5          0  \n",
       "356     60           5          0  \n",
       "357    108           5          0  \n",
       "358     50           5          0  \n",
       "359     40           5          0  \n",
       "\n",
       "[360 rows x 12 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d34dfcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.50199203187251, 1: 126.0}\n",
      "Confusion Matrix:\n",
      " [[106   2]\n",
      " [  0   0]]\n",
      "Accuracy: 0.9814814814814815\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# Separate features and target\n",
    "X = df_class_weight.drop('Legendary', axis=1)\n",
    "y = df_class_weight['Legendary']\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight('balanced', classes=pd.unique(y_train), y=y_train)\n",
    "\n",
    "# Create a dictionary mapping class labels to their respective weights\n",
    "class_weight_dict = dict(zip(pd.unique(y_train), class_weights))\n",
    "\n",
    "print(class_weight_dict)\n",
    "\n",
    "# Create a logistic regression model with class_weight parameter\n",
    "model = LogisticRegression(class_weight=class_weight_dict, max_iter = 1000)\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the confusion matrix and accuracy\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Accuracy:\", acc_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c9131f",
   "metadata": {},
   "source": [
    "### Oversampling\n",
    "\n",
    "Oversampling is a technique that works backward to undersampling. Instead of reducing the size of the majority class, we are generating new samples for the minority class using different algorithms. The biggest family of such algorithms is SMOTE. There are also other algorithms that make this process in different ways."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71c4e47",
   "metadata": {},
   "source": [
    "__SMOTE__\n",
    "\n",
    "(Synthetic Minority Oversampling Technique) is the simplest and the most popular oversampling algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a101cd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_smote = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8b67c34b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>Total</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>117</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>440</td>\n",
       "      <td>55</td>\n",
       "      <td>65</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>45</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>119</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>450</td>\n",
       "      <td>80</td>\n",
       "      <td>92</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>80</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>124</td>\n",
       "      <td>14</td>\n",
       "      <td>8.0</td>\n",
       "      <td>455</td>\n",
       "      <td>65</td>\n",
       "      <td>50</td>\n",
       "      <td>35</td>\n",
       "      <td>115</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>125</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>490</td>\n",
       "      <td>65</td>\n",
       "      <td>83</td>\n",
       "      <td>57</td>\n",
       "      <td>95</td>\n",
       "      <td>85</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>126</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>495</td>\n",
       "      <td>65</td>\n",
       "      <td>95</td>\n",
       "      <td>57</td>\n",
       "      <td>100</td>\n",
       "      <td>85</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>591</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>464</td>\n",
       "      <td>114</td>\n",
       "      <td>85</td>\n",
       "      <td>70</td>\n",
       "      <td>85</td>\n",
       "      <td>80</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>593</td>\n",
       "      <td>3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>480</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "      <td>85</td>\n",
       "      <td>105</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>596</td>\n",
       "      <td>4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>472</td>\n",
       "      <td>70</td>\n",
       "      <td>77</td>\n",
       "      <td>60</td>\n",
       "      <td>97</td>\n",
       "      <td>60</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>600</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>440</td>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "      <td>95</td>\n",
       "      <td>70</td>\n",
       "      <td>85</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>603</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>405</td>\n",
       "      <td>65</td>\n",
       "      <td>85</td>\n",
       "      <td>70</td>\n",
       "      <td>75</td>\n",
       "      <td>70</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       #  Type 1  Type 2  Total   HP  Attack  Defense  Sp. Atk  Sp. Def  \\\n",
       "0    117       3     0.0    440   55      65       95       95       45   \n",
       "1    119       3     0.0    450   80      92       65       65       80   \n",
       "2    124      14     8.0    455   65      50       35      115       95   \n",
       "3    125       7     0.0    490   65      83       57       95       85   \n",
       "4    126       2     0.0    495   65      95       57      100       85   \n",
       "..   ...     ...     ...    ...  ...     ...      ...      ...      ...   \n",
       "355  591       1     1.0    464  114      85       70       85       80   \n",
       "356  593       3    16.0    480  100      60       70       85      105   \n",
       "357  596       4    14.0    472   70      77       60       97       60   \n",
       "358  600      17     0.0    440   60      80       95       70       85   \n",
       "359  603       7     0.0    405   65      85       70       75       70   \n",
       "\n",
       "     Speed  Generation  Legendary  \n",
       "0       85           1          0  \n",
       "1       68           1          0  \n",
       "2       95           1          0  \n",
       "3      105           1          0  \n",
       "4       93           1          0  \n",
       "..     ...         ...        ...  \n",
       "355     30           5          0  \n",
       "356     60           5          0  \n",
       "357    108           5          0  \n",
       "358     50           5          0  \n",
       "359     40           5          0  \n",
       "\n",
       "[360 rows x 12 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "28d049ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected n_neighbors <= n_samples,  but n_samples = 1, n_neighbors = 6",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [42]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m smote \u001b[38;5;241m=\u001b[39m SMOTE(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Fit and resample the data using SMOTE\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m X_resampled, y_resampled \u001b[38;5;241m=\u001b[39m \u001b[43msmote\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Create a logistic regression model\u001b[39;00m\n\u001b[0;32m     23\u001b[0m model \u001b[38;5;241m=\u001b[39m LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m)\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\imblearn\\base.py:203\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \n\u001b[0;32m    184\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;124;03m    The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m--> 203\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\imblearn\\base.py:88\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     82\u001b[0m X, y, binarize_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X_y(X, y)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy_ \u001b[38;5;241m=\u001b[39m check_sampling_strategy(\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampling_type\n\u001b[0;32m     86\u001b[0m )\n\u001b[1;32m---> 88\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m y_ \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     91\u001b[0m     label_binarize(output[\u001b[38;5;241m1\u001b[39m], classes\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39munique(y)) \u001b[38;5;28;01mif\u001b[39;00m binarize_y \u001b[38;5;28;01melse\u001b[39;00m output[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     92\u001b[0m )\n\u001b[0;32m     94\u001b[0m X_, y_ \u001b[38;5;241m=\u001b[39m arrays_transformer\u001b[38;5;241m.\u001b[39mtransform(output[\u001b[38;5;241m0\u001b[39m], y_)\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py:355\u001b[0m, in \u001b[0;36mSMOTE._fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    352\u001b[0m X_class \u001b[38;5;241m=\u001b[39m _safe_indexing(X, target_class_indices)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_k_\u001b[38;5;241m.\u001b[39mfit(X_class)\n\u001b[1;32m--> 355\u001b[0m nns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn_k_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    356\u001b[0m X_new, y_new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_samples(\n\u001b[0;32m    357\u001b[0m     X_class, y\u001b[38;5;241m.\u001b[39mdtype, class_sample, X_class, nns, n_samples, \u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m    358\u001b[0m )\n\u001b[0;32m    359\u001b[0m X_resampled\u001b[38;5;241m.\u001b[39mappend(X_new)\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_base.py:749\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    747\u001b[0m n_samples_fit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_samples_fit_\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_neighbors \u001b[38;5;241m>\u001b[39m n_samples_fit:\n\u001b[1;32m--> 749\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    750\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected n_neighbors <= n_samples, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    751\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but n_samples = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, n_neighbors = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (n_samples_fit, n_neighbors)\n\u001b[0;32m    752\u001b[0m     )\n\u001b[0;32m    754\u001b[0m n_jobs \u001b[38;5;241m=\u001b[39m effective_n_jobs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n\u001b[0;32m    755\u001b[0m chunked_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected n_neighbors <= n_samples,  but n_samples = 1, n_neighbors = 6"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# Separate features and target\n",
    "X = df_smote.drop('Legendary', axis=1)\n",
    "y = df_smote['Legendary']\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Fit and resample the data using SMOTE\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Create a logistic regression model\n",
    "model = LogisticRegression(max_iter=500)\n",
    "\n",
    "# Train the model on the resampled (balanced) training data\n",
    "model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Test the model on the testing data\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Calculate the accuracy score\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", acc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dc1473",
   "metadata": {},
   "source": [
    "__SMOTEENN__\n",
    "\n",
    "One of the main drawbacks of SMOTE is that local outliers may influence it. Sometimes SMOTEcan take a minority sample that has only majority samples around, being in the middle of the majority class zone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b8ceec69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_smoteenn = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "6a0ef321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting crucio\n",
      "  Using cached crucio-0.1.94-py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: pandas in c:\\python310\\lib\\site-packages (from crucio) (1.5.1)\n",
      "Requirement already satisfied: statistics in c:\\python310\\lib\\site-packages (from crucio) (1.0.3.5)\n",
      "Requirement already satisfied: numba in c:\\python310\\lib\\site-packages (from crucio) (0.56.4)\n",
      "Requirement already satisfied: numpy in c:\\python310\\lib\\site-packages (from crucio) (1.23.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\python310\\lib\\site-packages (from crucio) (1.1.3)\n",
      "Requirement already satisfied: setuptools in c:\\python310\\lib\\site-packages (from numba->crucio) (60.8.1)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in c:\\python310\\lib\\site-packages (from numba->crucio) (0.39.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\python310\\lib\\site-packages (from pandas->crucio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python310\\lib\\site-packages (from pandas->crucio) (2022.6)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\python310\\lib\\site-packages (from scikit-learn->crucio) (1.9.3)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\python310\\lib\\site-packages (from scikit-learn->crucio) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\python310\\lib\\site-packages (from scikit-learn->crucio) (3.1.0)\n",
      "Requirement already satisfied: docutils>=0.3 in c:\\python310\\lib\\site-packages (from statistics->crucio) (0.19)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python310\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->crucio) (1.16.0)\n",
      "Installing collected packages: crucio\n",
      "Successfully installed crucio-0.1.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\python310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install crucio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8b9632c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty range for randrange()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [88]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcrucio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTEENN \n\u001b[0;32m      3\u001b[0m smoteenn \u001b[38;5;241m=\u001b[39m SMOTEENN() \n\u001b[1;32m----> 5\u001b[0m balanced_df \u001b[38;5;241m=\u001b[39m \u001b[43msmoteenn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbalance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_smoteenn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLegendary\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\crucio\\SMOTEENN.py:151\u001b[0m, in \u001b[0;36mSMOTEENN.balance\u001b[1;34m(self, df, target)\u001b[0m\n\u001b[0;32m    148\u001b[0m neighbours_indexes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_k_neighbours(example) \n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m#select random neighbour\u001b[39;00m\n\u001b[1;32m--> 151\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[43mrandrange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mneighbours_indexes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    152\u001b[0m selected_neighbour \u001b[38;5;241m=\u001b[39m neighbours_indexes[index]\n\u001b[0;32m    153\u001b[0m selected_neighbour \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mminority_samples[selected_neighbour]\n",
      "File \u001b[1;32mC:\\Python310\\lib\\random.py:321\u001b[0m, in \u001b[0;36mRandom.randrange\u001b[1;34m(self, start, stop, step)\u001b[0m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m istart \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_randbelow(istart)\n\u001b[1;32m--> 321\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mempty range for randrange()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    323\u001b[0m \u001b[38;5;66;03m# stop argument supplied.\u001b[39;00m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: empty range for randrange()"
     ]
    }
   ],
   "source": [
    "from crucio import SMOTEENN \n",
    "\n",
    "smoteenn = SMOTEENN() \n",
    "\n",
    "balanced_df = smoteenn.balance(df_smoteenn, 'Legendary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "32e85226",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'k_neighbors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [91]\u001b[0m, in \u001b[0;36m<cell line: 22>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X_scaled, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Create an instance of EditedNearestNeighbours\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m enn \u001b[38;5;241m=\u001b[39m EditedNearestNeighbours(\u001b[43mk_neighbors\u001b[49m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m n_samples)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Create a SMOTEENN instance with enn parameter set to the previously created EditedNearestNeighbours object\u001b[39;00m\n\u001b[0;32m     25\u001b[0m smoteenn \u001b[38;5;241m=\u001b[39m SMOTEENN(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, enn\u001b[38;5;241m=\u001b[39menn)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'k_neighbors' is not defined"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define the features (X) and target variable (y)\n",
    "X = df_smoteenn.drop('Legendary', axis=1)\n",
    "y = df_smoteenn['Legendary']\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Calculate the minimum number of samples in any class\n",
    "n_samples = df_smoteenn['Legendary'].value_counts().min() - 1\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create an instance of EditedNearestNeighbours\n",
    "enn = EditedNearestNeighbours(k_neighbors <= n_samples)\n",
    "\n",
    "# Create a SMOTEENN instance with enn parameter set to the previously created EditedNearestNeighbours object\n",
    "smoteenn = SMOTEENN(random_state=42, enn=enn)\n",
    "\n",
    "# Apply SMOTEENN to the training dataset\n",
    "X_train_resampled, y_train_resampled = smoteenn.fit_resample(X_train, y_train)\n",
    "\n",
    "# Create a logistic regression model\n",
    "model = LogisticRegression(max_iter = 1000)\n",
    "\n",
    "# Train the model on the balanced training data\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Test the model on the testing data\n",
    "score = model.score(X_test, y_test)\n",
    "print(\"Accuracy:\", score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac95a9be",
   "metadata": {},
   "source": [
    "__ICOTE__\n",
    "\n",
    "(Immune centroids over-sampling method for multiclass classification) is an oversampling method out of the SMOTE family that generates new minority samples by trying to replicate the principles of Immune systems. ICOTE algorithm can be separated into two phases:\n",
    "\n",
    "1. Clone generation\n",
    "\n",
    "\n",
    "2. Mutains generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7425ab74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_icote =  df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ea93f089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              #     Type 1    Type 2       Total          HP      Attack  \\\n",
      "0    117.000000   3.000000  0.000000  440.000000   55.000000   65.000000   \n",
      "1    119.000000   3.000000  0.000000  450.000000   80.000000   92.000000   \n",
      "2    124.000000  14.000000  8.000000  455.000000   65.000000   50.000000   \n",
      "3    125.000000   7.000000  0.000000  490.000000   65.000000   83.000000   \n",
      "4    126.000000   2.000000  0.000000  495.000000   65.000000   95.000000   \n",
      "..          ...        ...       ...         ...         ...         ...   \n",
      "353  685.995957  10.398839 -7.815095  715.261262  110.058058  120.029029   \n",
      "354  691.660426  11.000000 -1.385924  760.170101  107.718477  143.112906   \n",
      "355  691.660426  11.000000 -1.385924  760.170101  107.718477  143.112906   \n",
      "356  745.577154  16.007769 -1.669256  695.178698   63.307435  150.904553   \n",
      "357  756.426500  20.211589  0.000000  662.904298   84.605794  128.028972   \n",
      "\n",
      "        Defense     Sp. Atk     Sp. Def       Speed  Generation  Legendary  \n",
      "0     95.000000   95.000000   45.000000   85.000000    1.000000          0  \n",
      "1     65.000000   65.000000   80.000000   68.000000    1.000000          0  \n",
      "2     35.000000  115.000000   95.000000   95.000000    1.000000          0  \n",
      "3     57.000000   95.000000   85.000000  105.000000    1.000000          0  \n",
      "4     57.000000  100.000000   85.000000   93.000000    1.000000          0  \n",
      "..          ...         ...         ...         ...         ...        ...  \n",
      "353  114.017417  135.058058  141.069670   95.029029    5.803483          1  \n",
      "354  146.577716  129.253667  146.577716   86.929619    5.385924          1  \n",
      "355  146.577716  129.253667  146.577716   86.929619    5.385924          1  \n",
      "356  150.904553  129.204219  112.511654   88.346282    5.669256          1  \n",
      "357  114.211589  118.817383  109.605794  107.634766    5.842318          1  \n",
      "\n",
      "[718 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "from crucio import ICOTE \n",
    "\n",
    "icote = ICOTE() \n",
    "\n",
    "balanced_df = icote.balance(df_icote, 'Legendary')\n",
    "\n",
    "print(balanced_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "af000b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEWCAYAAACqitpwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAeEklEQVR4nO3deZxcZZ3v8c83CQSQSGDSZkInGISoE+ASMCIozjC4AaM3uCFuBMSJC+7KRdQryMCVeQ2KOKM4UZAEFIwowyIqi+ByBTFBVnGJbEkMSbMEEgSchN/88TxNTirV3VWd53R1J9/361WvrvOc7XfqnKrv2bpKEYGZmVlJozpdgJmZbX4cLmZmVpzDxczMinO4mJlZcQ4XMzMrzuFiZmbFDetwkfQ1Sf+30LR2kbRG0ujcfb2kd5eYdp7eDyXNLjW9NuZ7qqQHJT0w1PMuQdJ5kk7tdB0jhaS3S7qq4PSKvg82oY6pkkLSmE7X0kvSyZIu6HQdI1XHwkXSvZKekLRa0ipJv5T0XknP1BQR742If2lxWq/sb5iIuD8ito+IdQVq32iji4hDI2Lepk67zTp2AT4OTI+Iv23S/yBJS4eypuEsf5A+mXcyeh8HFJjmkH04R8S3IuLVgxm37g/Lynt6jaRHJP1A0pS65tdJ+b31dGU7WippgaQXtzGNttZHk3mukXT54Jagfp0+cnldRIwDngucDpwAnFN6JsNpb6iwXYCHImJlpwsZakoGs/1+IO9k9D5uKF5cGzbDbfN1EbE9MAlYAfx7h+up05/zso4D9gd+B/xc0ivqnmfl8brGAYbNNhURHXkA9wKvbGjbD3ga2DN3nwecmp9PAK4AVgEPAz8nheP5eZwngDXA/wGmAgEcC9wP/KzSNiZP73rg88BNwGPApcBOud9BwNJm9QKHAH8F/jvP79bK9N6dn48CPgPcB6wE5gM75H69dczOtT0IfLqf12mHPH5Pnt5n8vRfmZf56VzHeU3G3Wg5Kv12Br6Xp3sP8KFKv22BecAjwF35NV3a4rgnAwtyzauBO4GZlf77ADfnft8BLqqs4x3zOu7J874CmFwZ93rgNOD/52U/HljUsFwfAy7tY5mfWUcN7WOBM/L6WAF8Ddh2oJpyLeuAJ/M6+A8atrMm28bRuf4zgYeAU/ubf5NajwZ+UekO4L3AH0nvja8AajJef9vtv+SaVgNXARMq4+0P/DJP+1bgoFbf08BhwB8q3f8E/Ib0flsCnFzpt8HrBhxD2vZWA3cD72ncrklH7SuB5cAxDdvvF0jvl0eBX1TWZ5/LA+wK/DTP8+q8Pi/oY1kPosl7K4+zsNJ9Vl7Wx4BFwMsHWB8DLncf20TjNrUb8JPc/SDwLWB8w7o6HrgNeJy0Uz8R+GGe9zXAjoPZDp4ZZ6AB6no0boiV9vuB9+Xn57H+g+fzpDfdVvnxcvKbqHFalQ11PvCsvLH1tlXDZRmwZx7me70bUrOVWJ0H6QP0gob+17P+A+RdwGLgecD2wPeB8xtq+3qua2/gKeDv+nid5pOCb1we9w/Asf1tbC1sjKNIG/pnga1znXcDr8n9Tye9yXYEJucNcGmL455M+rA9DBid19uNud/WpDf8R/M6fBPpzdW7jv8GeCOwXV7e7wL/1fAa3w/sAYwhfSg/XH3tSB9eb+zj9XhmHTW0nwlcBuyU53s58Pk2anp3pbt3/fYXLmuBD+Zl2La/+ffxQdIYLlcA40lHsj3AIX2MezLNt9s/Ac/PtVwPnJ77dZM+nA7L6/1VubtroPd0fr3mAfMbtse98rT+FylID2/2upGCaDdAwD8AfwH2rUxnLXAKaTs6LPffMff/Sl6ObtI2+NK8rfS7PMANwBfzsH9P+pBtN1wOJu3wPSt3v4O0DY0hheEDwDb9rI+BlruvcGncpnbPyzcW6CLtYH+pYV3dSAqUblJI30za+duGFEwnDWY7eGYe/fWs80Hf4XIjeU+eDcPlFNKH7O4DTauyoT6vrzc9lTdR7p5O2pMY3Wwl0l64XAu8v9LvBaQP0TGVOqp75DcBRzZZrtG5pumVtvcA1/e3sbXwBngJcH9D24nAN/PzZ8Iid7+b9eEy0LgnA9c0vK5P5Od/D/yZyp41aW/o1D7qnwE80vAan9IwzNnAafn5HqSji7F9TO960pt1VX7cTHoTPw7sVhnuAOCeNmpqN1zur/Rrd/5Hs3G4HFjpXgB8so9xT6b5dvuZSvf7gR/l5yeQd4oq/X8MzO5j+veS9sJXkbb3PwN79bN9fgk4s6/XrWHY/wI+XNmun2h4jVeS9q5H5X57N5lGn8tDCua15FDI/b7d+Hq18N56YV6O7j7Ge6S3tmbro4Xlfpr12+8q4IjGbaqP6RwO/KZhXb290v094OxK9wfJO1Htbge9j+Fxbm5D3aS90Ub/RloZV0kCmBsRpw8wrSVt9L+PtBc0obUy+7Vznl512mNIewm9qnd3/YV0hNNoQq6pcVrdm1jfc4GdJa2qtI0mnWqEVH/1tak+H2hc2HjZtsnngXcGlkXeOrNnlk3SdqS9+ENIR00A4ySNjvU3YjSu03nAhZI+A7wTWBART220xOt9KCK+UZnnc0h72YvydgXpA7/3rsJWampXdRm6+pt/i1rZlgYz/nOBN0uqntffCriun2kdHhHX5LsyZwE/lTQ9Ih6Q9BLSUfGepKPYsaQjwY1IOhQ4iXRENYr0Gt1eGeShiFjbpO4JpD3vPzWZbH/LszNpp+HxSr/7gHZvSOgmhcuqvByfIJ2e3zm3P5t+PmNaWO4/R8TkhnGOpuF9IWki6ZTcy0lHw6NIwVa1ovL8iSbdm7IddPyC/gbynRbdpHOkG4iI1RHx8Yh4HvC/gY9VLpxF4/ADtPeqbji7kPa2HiTtSW5XqWs06UOg1en+mbRCqtNey4YrrxUP5poap7Wszek0WkLaMx5feYyLiMNy/+Wk02G9prQxbn+WA92qfIqSlqfXx0lHeS+JiGeTjnQgfdj22uC1j4gbSUd3LwfeRroG144HSW+kPSrLs0OkC7Wt1NS4LfR+OG1XaWu8k686zkDzL2mg7bbREtIea3VdP6uFnToiYl1EfJ90TerA3Pxt0um/KRGxA+k0txrHlTSWtCd9BjAxIsYDVzYbtokHSadld2tzeZYDO0p6VmX4XZpMYyCvB26OiMclvZx0vfII0im78aRrQE23nU1c7sZ1+/9y2155u31Hi9NpZlDbwbAIF0nPlvRa0sXdCyLi9ibDvFbS7vmD6VHSRvt07r2CdO6/Xe+QND3vnZ4CXJz3Rv9A2tv+J0lbkS6ij62MtwKY2s/dShcCH5W0q6TtSSv6Ow17WgPKtSwATpM0TtJzSRes27qdVNI21QfpNNxqSSdI2lbSaEl7Vm6jXACcKGlHSd3AByqTG2jc/txACtkPSdpK0htIN3H0Gkf6oF0laSfSHlwr5pMupP53RGy0Y9KfiHiadP3rzHwUg6RuSa9psaYNtr2I6CGF/zvya/Mumn/QtTr/kgbabhtdALxO0mvysmyTb4edPNCI+W6+WaSjvbty8zjg4Yh4UtJ+pJ2BZnqPanqAtXlvvqXbr/PreS7wRUk757oPyB/cfS5PRNwHLAQ+J2lrSQcCG92J1c+ydks6iXQK+VOV5V2bl2OMpM+Sjlx6Na6PQS93E+NIpygfze/h4wc5HRjkdtDpcLlc0mpSMn6adDHtmD6GnUa6g2EN6UPqqxHRe1j2eeAzSv8v84k25n8+6brOA6RD6Q8BRMSjpHPP3yB9UDxOujulV++h/EOSbm4y3XPztH9GupvqSdI5zMH4YJ7/3aQjum/n6beqm/ThWH3sCryWdP3gHtLe3jdId6ZBCtqlud81wMWkmw56A6+/cfsUEX8F3kA6R/ww8BbSzQ69vkS6GPkg6drbj1pcxvNJp1oG+z8cJ5BuwLhR0mOkZX5BizWdBbxJ6f86vpzb/pn0Zn6IdB3ol5sw/5IG2m43EBFLSKe2PkX6wFtCWq7+Pjcul7SGdHfUaaTz8nfmfu8HTsnv+c+SdmKazXc16b24gHQq522kI55WfYJ0KunXpO3sX4FRLSzP20jXFB8m7UTMH2A+O+dlXZPntRfpLqref3L9MWl7+QPpFNuTbHj6aoP1UWC5qz4H7EvaEf8BG77P2jLI7eCZu63M+iTpfaQbDv6h07U0I2lb0gXdfSPij52ux8w6f+Riw5CkSZJeJmmUpBeQrjtc0um6+vE+4NcOFrPhYzjeLWadtzXwn6TTZ6tI18K+2smC+iLpXtKFysM7W4mZVfm0mJmZFefTYmZmVtyIPi02YcKEmDp1aqfLMDMbURYtWvRgRHQNPOTgjehwmTp1KgsXLux0GWZmI4qk+wYeatP4tJiZmRXncDEzs+IcLmZmVpzDxczMinO4mJlZcQ4XMzMrzuFiZmbFOVzMzKw4h4uZmRU3ov9Dv4QXHT/Q7wHZlmjRvx3V6RK4/5S9Ol2CDUO7fHajH+odlnzkYmZmxdUWLvl3lm+SdKukOyV9LrefJ+keSbfkx4zcLklflrRY0m2S9q2rNjMzq1edp8WeAg6OiDWStgJ+IemHud/xEXFxw/CHAtPy4yXA2fmvmZmNMLUduUSyJndulR/9/TLZLGB+Hu9GYLykSXXVZ2Zm9an1mouk0ZJuAVYCV0fEr3Kv0/KprzMljc1t3cCSyuhLc1vjNOdIWihpYU9PT53lm5nZINUaLhGxLiJmAJOB/STtCZwIvBB4MbATcEKb05wbETMjYmZXV62/dWNmZoM0JHeLRcQq4DrgkIhYnk99PQV8E9gvD7YMmFIZbXJuMzOzEabOu8W6JI3Pz7cFXgX8rvc6iiQBhwN35FEuA47Kd43tDzwaEcvrqs/MzOpT591ik4B5kkaTQmxBRFwh6SeSugABtwDvzcNfCRwGLAb+AhxTY21mZlaj2sIlIm4D9mnSfnAfwwdwXF31mJnZ0PF/6JuZWXEOFzMzK87hYmZmxTlczMysOIeLmZkV53AxM7PiHC5mZlacw8XMzIpzuJiZWXEOFzMzK87hYmZmxTlczMysOIeLmZkV53AxM7PiHC5mZlacw8XMzIpzuJiZWXEOFzMzK87hYmZmxTlczMysuNrCRdI2km6SdKukOyV9LrfvKulXkhZL+o6krXP72Ny9OPefWldtZmZWrzqPXJ4CDo6IvYEZwCGS9gf+FTgzInYHHgGOzcMfCzyS28/Mw5mZ2QhUW7hEsiZ3bpUfARwMXJzb5wGH5+ezcje5/yskqa76zMysPrVec5E0WtItwErgauBPwKqIWJsHWQp05+fdwBKA3P9R4G+aTHOOpIWSFvb09NRZvpmZDVKt4RIR6yJiBjAZ2A94YYFpzo2ImRExs6ura1MnZ2ZmNRiSu8UiYhVwHXAAMF7SmNxrMrAsP18GTAHI/XcAHhqK+szMrKw67xbrkjQ+P98WeBVwFylk3pQHmw1cmp9flrvJ/X8SEVFXfWZmVp8xAw8yaJOAeZJGk0JsQURcIem3wEWSTgV+A5yThz8HOF/SYuBh4MgaazMzsxrVFi4RcRuwT5P2u0nXXxrbnwTeXFc9ZmY2dPwf+mZmVpzDxczMinO4mJlZcQ4XMzMrzuFiZmbFOVzMzKw4h4uZmRXncDEzs+IcLmZmVpzDxczMinO4mJlZcQ4XMzMrzuFiZmbFOVzMzKw4h4uZmRXncDEzs+IcLmZmVpzDxczMinO4mJlZcbWFi6Qpkq6T9FtJd0r6cG4/WdIySbfkx2GVcU6UtFjS7yW9pq7azMysXmNqnPZa4OMRcbOkccAiSVfnfmdGxBnVgSVNB44E9gB2Bq6R9PyIWFdjjWZmVoPajlwiYnlE3JyfrwbuArr7GWUWcFFEPBUR9wCLgf3qqs/MzOozJNdcJE0F9gF+lZs+IOk2SedK2jG3dQNLKqMtpf8wMjOzYar2cJG0PfA94CMR8RhwNrAbMANYDnyhzenNkbRQ0sKenp7S5ZqZWQG1houkrUjB8q2I+D5ARKyIiHUR8TTwddaf+loGTKmMPjm3bSAi5kbEzIiY2dXVVWf5ZmY2SHXeLSbgHOCuiPhipX1SZbDXA3fk55cBR0oaK2lXYBpwU131mZlZfeq8W+xlwDuB2yXdkts+BbxV0gwggHuB9wBExJ2SFgC/Jd1pdpzvFDMzG5lqC5eI+AWgJr2u7Gec04DT6qrJzMyGhv9D38zMinO4mJlZcQ4XMzMrzuFiZmbFOVzMzKw4h4uZmRXncDEzs+IcLmZmVpzDxczMinO4mJlZcQ4XMzMrzuFiZmbFOVzMzKw4h4uZmRXncDEzs+IcLmZmVpzDxczMinO4mJlZcS2Fi6SXtdJmZmYGrR+5/HuLbWZmZozpr6ekA4CXAl2SPlbp9Wxg9ADjTgHmAxOBAOZGxFmSdgK+A0wF7gWOiIhHJAk4CzgM+AtwdETcPJiFMjOzzhroyGVrYHtSCI2rPB4D3jTAuGuBj0fEdGB/4DhJ04FPAtdGxDTg2twNcCgwLT/mAGe3vTRmZjYs9HvkEhE/BX4q6byIuK+dCUfEcmB5fr5a0l1ANzALOCgPNg+4Hjght8+PiABulDRe0qQ8HTMzG0H6DZeKsZLmkk5lPTNORBzcysiSpgL7AL8CJlYC4wHSaTNIwbOkMtrS3LZBuEiaQzqyYZdddmmxfDMzG0qthst3ga8B3wDWtTMDSdsD3wM+EhGPpUsrSUSEpGhnehExF5gLMHPmzLbGNTOzodFquKyNiLavgUjaihQs34qI7+fmFb2nuyRNAlbm9mXAlMrok3ObmZmNMK3einy5pPdLmiRpp95HfyPku7/OAe6KiC9Wel0GzM7PZwOXVtqPUrI/8Kivt5iZjUytHrn0hsHxlbYAntfPOC8D3gncLumW3PYp4HRggaRjgfuAI3K/K0m3IS8m3Yp8TIu1mZnZMNNSuETEru1OOCJ+AaiP3q9oMnwAx7U7HzMzG35aChdJRzVrj4j5ZcsxM7PNQaunxV5ceb4N6cjjZtJ/4JuZmW2g1dNiH6x2SxoPXFRHQWZmNvIN9iv3Hwfavg5jZmZbhlavuVxOujsM0hdW/h2woK6izMxsZGv1mssZledrgfsiYmkN9ZiZ2WagpdNi+Qssf0f6RuQdgb/WWZSZmY1srf4S5RHATcCbSf/0+CtJA33lvpmZbaFaPS32aeDFEbESQFIXcA1wcV2FmZnZyNXq3WKjeoMle6iNcc3MbAvT6pHLjyT9GLgwd7+F9F1gZmZmG+k3XCTtTvpxr+MlvQE4MPe6AfhW3cWZmdnINNCRy5eAEwHy77F8H0DSXrnf62qszczMRqiBrptMjIjbGxtz29RaKjIzsxFvoHAZ30+/bQvWYWZmm5GBwmWhpH9ubJT0bmBRPSWZmdlIN9A1l48Al0h6O+vDZCawNfD6GusyM7MRrN9wiYgVwEsl/SOwZ27+QUT8pPbKzMxsxGr191yuA66ruRYzM9tM+L/szcysuNrCRdK5klZKuqPSdrKkZZJuyY/DKv1OlLRY0u8lvaauuszMrH51HrmcBxzSpP3MiJiRH1cCSJoOHAnskcf5qqTRNdZmZmY1qi1cIuJnwMMtDj4LuCginoqIe4DFwH511WZmZvXqxDWXD0i6LZ822zG3dQNLKsMszW0bkTRH0kJJC3t6euqu1czMBmGow+VsYDdgBrAc+EK7E4iIuRExMyJmdnV1FS7PzMxKGNJwiYgVEbEuIp4Gvs76U1/LgCmVQSfnNjMzG4GGNFwkTap0vh7ovZPsMuBISWMl7QpMI/2sspmZjUCt/lhY2yRdCBwETJC0FDgJOEjSDCCAe4H3AETEnZIWAL8F1gLHRcS6umozM7N61RYuEfHWJs3n9DP8acBpddVjZmZDx/+hb2ZmxTlczMysOIeLmZkV53AxM7PiHC5mZlacw8XMzIpzuJiZWXEOFzMzK87hYmZmxTlczMysOIeLmZkV53AxM7PiHC5mZlacw8XMzIpzuJiZWXEOFzMzK87hYmZmxTlczMysOIeLmZkV53AxM7PiagsXSedKWinpjkrbTpKulvTH/HfH3C5JX5a0WNJtkvatqy4zM6tfnUcu5wGHNLR9Erg2IqYB1+ZugEOBafkxBzi7xrrMzKxmtYVLRPwMeLiheRYwLz+fBxxeaZ8fyY3AeEmT6qrNzMzqNdTXXCZGxPL8/AFgYn7eDSypDLc0t21E0hxJCyUt7Onpqa9SMzMbtI5d0I+IAGIQ482NiJkRMbOrq6uGyszMbFMNdbis6D3dlf+uzO3LgCmV4SbnNjMzG4GGOlwuA2bn57OBSyvtR+W7xvYHHq2cPjMzsxFmTF0TlnQhcBAwQdJS4CTgdGCBpGOB+4Aj8uBXAocBi4G/AMfUVZeZmdWvtnCJiLf20esVTYYN4Li6ajEzs6Hl/9A3M7PiHC5mZlacw8XMzIpzuJiZWXEOFzMzK87hYmZmxTlczMysOIeLmZkV53AxM7PiHC5mZlacw8XMzIpzuJiZWXEOFzMzK87hYmZmxTlczMysOIeLmZkV53AxM7PiHC5mZlacw8XMzIpzuJiZWXFjOjFTSfcCq4F1wNqImClpJ+A7wFTgXuCIiHikE/WZmdmm6eSRyz9GxIyImJm7PwlcGxHTgGtzt5mZjUDD6bTYLGBefj4POLxzpZiZ2aboVLgEcJWkRZLm5LaJEbE8P38AmNhsRElzJC2UtLCnp2coajUzszZ15JoLcGBELJP0HOBqSb+r9oyIkBTNRoyIucBcgJkzZzYdxszMOqsjRy4RsSz/XQlcAuwHrJA0CSD/XdmJ2szMbNMNebhIepakcb3PgVcDdwCXAbPzYLOBS4e6NjMzK6MTp8UmApdI6p3/tyPiR5J+DSyQdCxwH3BEB2ozM7MChjxcIuJuYO8m7Q8BrxjqeszMrLzhdCuymZltJhwuZmZWnMPFzMyKc7iYmVlxDhczMyvO4WJmZsU5XMzMrDiHi5mZFedwMTOz4hwuZmZWnMPFzMyKc7iYmVlxDhczMyvO4WJmZsU5XMzMrDiHi5mZFedwMTOz4hwuZmZWnMPFzMyKc7iYmVlxwy5cJB0i6feSFkv6ZKfrMTOz9g2rcJE0GvgKcCgwHXirpOmdrcrMzNo1rMIF2A9YHBF3R8RfgYuAWR2uyczM2jSm0wU06AaWVLqXAi+pDiBpDjAnd66R9Pshqm1LMAF4sNNFDAc6Y3anS7ANedvsdZJKTOW5JSbSn+EWLgOKiLnA3E7XsTmStDAiZna6DrNG3jZHnuF2WmwZMKXSPTm3mZnZCDLcwuXXwDRJu0raGjgSuKzDNZmZWZuG1WmxiFgr6QPAj4HRwLkRcWeHy9qS+HSjDVfeNkcYRUSnazAzs83McDstZmZmmwGHi5mZFedwMX/ljg1bks6VtFLSHZ2uxdrjcNnC+St3bJg7Dzik00VY+xwu5q/csWErIn4GPNzpOqx9Dhdr9pU73R2qxcw2Ew4XMzMrzuFi/sodMyvO4WL+yh0zK87hsoWLiLVA71fu3AUs8Ffu2HAh6ULgBuAFkpZKOrbTNVlr/PUvZmZWnI9czMysOIeLmZkV53AxM7PiHC5mZlacw8XMzIpzuNgWR9KaYVDDVH/Tr23OHC5mI4CkYfWT5GYDcbiYAZJ2k/QjSYsk/VzSCyvtN0q6XdKp1aMeScdL+rWk2yR9LrdNlXSXpK9LulPSVZK2zf1eJOlWSbcCx1WmMzXP8+b8eGluPyi3Xwb8VtIpkj5SGe80SR8ekhfIrE0OF7NkLvDBiHgR8Angq7n9LOCsiNiL9I3RAEh6NTCN9JMFM4AXSfr73Hsa8JWI2ANYBbwxt38zz2PvhnmvBF4VEfsCbwG+XOm3L/DhiHg+cC5wVJ7/KNJX9VywaYttVg8fatsWT9L2wEuB70rqbR6b/x4AHJ6ffxs4Iz9/dX78JndvTwqV+4F7IuKW3L4ImCppPDA+/z4JwPmkH2gD2Ar4D0kzgHXA8yvl3RQR9wBExL2SHpK0DzAR+E1EPDToBTerkcPFLB3Br4qIGW2MI+DzEfGfGzRKU4GnKk3rgG0HmNZHgRXA3rmWJyv9Hm8Y9hvA0cDfko5kzIYlnxazLV5EPAbcI+nNAEp6T13dyPrTWkdWRvsx8K581IOkbknP6Wceq4BVkg7MTW+v9N4BWB4RTwPvBEb3U+4lpJ/9fXGuwWxYcrjYlmi7/A27vY+PkT7sj80X2+9k/U89fwT4mKTbgN2BRwEi4irSabIbJN0OXAyMG2C+xwBfkXQL6cin11eB2XneL2Tjo5Vn5J+ivo707dXr2lhmsyHlb0U264ek7YAnIiIkHQm8NSJmDTRejfWMAm4G3hwRf+xUHWYD8TUXs/69iHSxXaQ7v97VqUIkTQeuAC5xsNhw5yMXMzMrztdczMysOIeLmZkV53AxM7PiHC5mZlacw8XMzIr7H4H8/gqCn/3hAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming balanced_df is the output DataFrame from ICOTE balancing\n",
    "\n",
    "# Visualize the distribution of the 'Legendary' feature in the balanced DataFrame\n",
    "sns.countplot(x='Legendary', data = balanced_df)\n",
    "\n",
    "plt.title('Distribution of Legendary Feature in the Balanced DataFrame')\n",
    "plt.xlabel('Legendary')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f14db33",
   "metadata": {},
   "source": [
    "__TKRKNN__\n",
    "\n",
    "(Top-K Reversed KNN) has a very different way of generating new samples compared to the SMOTE family or ICOTE. The difference is that it generates new samples non-linearly- meaning that the new sample isn’t somewhere on the line that links two samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "137b9eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tkrnn = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1950446f",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [97]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcrucio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TKRKNN \n\u001b[0;32m      3\u001b[0m tkrknn \u001b[38;5;241m=\u001b[39m TKRKNN()\n\u001b[1;32m----> 5\u001b[0m balanced_df \u001b[38;5;241m=\u001b[39m \u001b[43mtkrknn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbalance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_tkrnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLegendary\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\crucio\\TKRKNN.py:142\u001b[0m, in \u001b[0;36mTKRKNN.balance\u001b[1;34m(self, df, target)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;66;03m# Randomly change the attributes of the selected sample.\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attr_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_columns)):\n\u001b[1;32m--> 142\u001b[0m     dif \u001b[38;5;241m=\u001b[39m minority_set[\u001b[43mnnarray\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrandom_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m]\u001b[49m, attr_index] \u001b[38;5;241m-\u001b[39m minority_set[random_index, attr_index]\n\u001b[0;32m    143\u001b[0m     gap \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msynthetic_data[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][attr_index] \u001b[38;5;241m=\u001b[39m minority_set[random_index, attr_index] \u001b[38;5;241m+\u001b[39m gap \u001b[38;5;241m*\u001b[39m dif\n",
      "\u001b[1;31mIndexError\u001b[0m: index 3 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "from crucio import TKRKNN \n",
    "\n",
    "tkrknn = TKRKNN()\n",
    "\n",
    "balanced_df = tkrknn.balance(df_tkrnn, 'Legendary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "287ebb61",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [425]\u001b[0m, in \u001b[0;36m<cell line: 25>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m tkrknn \u001b[38;5;241m=\u001b[39m TKRKNN()\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Apply TKRKNN to the training dataset\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m X_train_resampled, y_train_resampled \u001b[38;5;241m=\u001b[39m \u001b[43mtkrknn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbalance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Create a logistic regression model\u001b[39;00m\n\u001b[0;32m     28\u001b[0m model \u001b[38;5;241m=\u001b[39m LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\crucio\\TKRKNN.py:94\u001b[0m, in \u001b[0;36mTKRKNN.balance\u001b[1;34m(self, df, target)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;241m=\u001b[39m target\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# Checking if the target string based t algorithm is present in the data frame.\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m:\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NoSuchColumn(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt a column of passed data frame\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# Checking if the target column is a binary one.\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from crucio import TKRKNN\n",
    "\n",
    "# Fill NaN values with the most frequent class in the 'Type 2' column\n",
    "df['Type 2'] = df['Type 2'].fillna(df['Type 2'].mode()[0])\n",
    "\n",
    "# Define the features (X) and target variable (y)\n",
    "X = df.drop('Legendary', axis=1)\n",
    "y = df['Legendary']\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create a TKRKNN instance\n",
    "tkrknn = TKRKNN()\n",
    "\n",
    "# Apply TKRKNN to the training dataset\n",
    "X_train_resampled, y_train_resampled = tkrknn.balance(X_train, y_train)\n",
    "\n",
    "# Create a logistic regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Train the model on the balanced training data\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Test the model on the testing data\n",
    "score = model.score(X_test, y_test)\n",
    "print(\"Accuracy:\", score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
