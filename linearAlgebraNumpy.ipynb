{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12eae98b",
   "metadata": {},
   "source": [
    "## **Formula No. 1: Normal Distribution.**\n",
    "\n",
    "The normal distribution function is the function that simply saying allows us to get the probability of getting a value from a numerical series knowing the mean and standard deviation of the series.\n",
    "- x: a float value.\n",
    "- mu (μ): a float value (represents the mean of the series).\n",
    "- sigma (σ): a float value (represents the standard deviation of the series)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3eb31b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import matplotlib, numpy and math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "42830df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal distribution: 0.09666702920071231\n"
     ]
    }
   ],
   "source": [
    "# function for normal distribution calculation\n",
    "def normal_dist (x, mu, sigma):\n",
    "    \n",
    "    #   formula for normal distribution \n",
    "    result = (1 / (sigma * math.sqrt(2 * math.pi))) * math.exp(- pow(x - mu, 2) / (2 * pow(sigma, 2))) \n",
    "    \n",
    "#   display the normal distrubution\n",
    "    print('normal distribution:', result)\n",
    "    \n",
    "# call and send the for the normal distribution    \n",
    "normal_dist(4.0, 5.0, 4.0)\n",
    "\n",
    "# input value = 4.0, 5.0, 4.0 \n",
    "# target value = 0.0967"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee88b55b",
   "metadata": {},
   "source": [
    "## **Formula No. 2: Sigmoid Function.**\n",
    "\n",
    "The name of the organization comes from an activation function - Sigmoid. The sigmoid function is used when you need to convert real numbers into probabilities, or from a -∞ to +∞ range into 0 to 1 range.\n",
    "- y: a real numeric value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fe74c092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid: 0.01798620996209156\n"
     ]
    }
   ],
   "source": [
    "# define the sigmoid fucntion\n",
    "def sigmoid(y):\n",
    "\n",
    "#   formula for the sigmoid function\n",
    "    sig = 1 / (1 + math.exp(- y))\n",
    "    \n",
    "#   display the sigmoid funnction\n",
    "    print('sigmoid:', sig)\n",
    "\n",
    "# call and send the parameter for the sigmoid function\n",
    "sigmoid(-4)\n",
    "# input value = -4\n",
    "# target value = 0.01798621"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb72150c",
   "metadata": {},
   "source": [
    "## **Formula No. 3: Weights update in Logistic Regression.**\n",
    "\n",
    "One of the Machine Learning algorithms is Logistic Regression. It uses an iterative process to find the coefficients of a linear function updating the values of the weights vector (w) at each iteration, taking into account errors of the prediction of the model itself.\n",
    "- w: a 1 - d numpy array.\n",
    "- X: a 2 - d numpy array.\n",
    "- y: a 1 - d numpy array.\n",
    "- alpha - a value from 0 to 1, default - 0.0005.\n",
    "\n",
    "The function should return the newly updated w array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14f996f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "UFuncTypeError",
     "evalue": "Cannot cast ufunc 'add' output from dtype('float64') to dtype('int32') with casting rule 'same_kind'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 19>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# value from 0 to 1, default: 0.0005\u001b[39;00m\n\u001b[0;32m     17\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0005\u001b[39m\n\u001b[1;32m---> 19\u001b[0m \u001b[43mweight_update_logistic_regresision\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36mweight_update_logistic_regresision\u001b[1;34m(w, x, alpha, y_true, y_pred)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mweight_update_logistic_regresision\u001b[39m(w, x, alpha, y_true, y_pred):\n\u001b[1;32m----> 3\u001b[0m         w \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m w \u001b[38;5;241m-\u001b[39m (alpha \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(x) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(y_true)) \u001b[38;5;241m*\u001b[39m (y_pred \u001b[38;5;241m-\u001b[39m y_true) \u001b[38;5;241m*\u001b[39m x)\n",
      "\u001b[1;31mUFuncTypeError\u001b[0m: Cannot cast ufunc 'add' output from dtype('float64') to dtype('int32') with casting rule 'same_kind'"
     ]
    }
   ],
   "source": [
    "# def weight_update_logistic_regresision(w, x, alpha, y_true, y_pred):\n",
    "    \n",
    "#         w += w - (alpha * (1 / len(x) + len(y_true)) * (y_pred - y_true) * x)\n",
    "    \n",
    "# # 1D numpy array\n",
    "# w = np.array([1, 1, 1])\n",
    "\n",
    "# # 2D numpy array\n",
    "# x = np.array([[1, 1, 0], [0, 1, 1]])\n",
    "\n",
    "# # 1D numpy array\n",
    "# y_true = np.array([1, 0, 1])\n",
    "\n",
    "# y_pred = np.array([2, 1, 2])\n",
    "\n",
    "# # value from 0 to 1, default: 0.0005\n",
    "# alpha = 0.0005\n",
    "\n",
    "# weight_update_logistic_regresision(w, x, alpha, y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871c2fa0",
   "metadata": {},
   "source": [
    "## **Formula No. 4: Mean Squared Error**\n",
    "\n",
    "Mean Squared Error(MSE) measures the average of the squares of the errors—that is, the average squared difference between the estimated values and the actual value. Usually used in Regression problems. \n",
    "- target: a 1 - d numpy array;\n",
    "- predictions: a 1 - d numpy array;\n",
    "\n",
    "The function should return the error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fac83642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean squered error: 8.166666666666666\n"
     ]
    }
   ],
   "source": [
    "def mean_squered_error(y_true, y_pred):\n",
    "    # Mean Squared Error formula\n",
    "    mse = np.square( np.subtract( y_true, y_pred ) ).mean()\n",
    "    \n",
    "#   display the result\n",
    "    print('mean squered error:', mse)\n",
    "\n",
    "# Given values\n",
    "Y_True = [67, 50, 36, 74, 84, 84, 64, 34, 23, 72, 62, 42]  # Y_true = Y target (original values)\n",
    "  \n",
    "# Calculated values prediction\n",
    "Y_Pred = [70, 49, 38, 76, 83, 80, 67, 30, 20, 75, 60, 38]  # Y_pred = Y'\n",
    "\n",
    "# call the function and send the data\n",
    "mean_squered_error(Y_True, Y_Pred)\n",
    "\n",
    "# target value = 8.1666"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce0213a",
   "metadata": {},
   "source": [
    "## **Formula No. 5: Binary Cross Entropy**\n",
    "\n",
    "This is another error function, that is used in Classification problems, the y parameter from the function below represents the actual value of the class and ŷ the predicted one, if might observe that actually always half of the function is canceled, which part depend on the actual class, if y=0, first half is canceled and the (1-y) will be 1 which saves the second part, for y=1 the opposite. The log is taken out of the predicted value, and as the value approaches the actual value, this log error will be smaller and smaller, showing ML algorithms the way to best parameters.\n",
    "- target: a 1-d numpy array.\n",
    "- predictions: a 1-d numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e365a223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary cross entropy: 5.141649490132791\n"
     ]
    }
   ],
   "source": [
    "def binary_cross_entropy(y_true, y_pred):\n",
    "#   used to Clip (limit) the values in an array\n",
    "    y_pred = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "    \n",
    "#   formula for calcualtion\n",
    "    term_0 = (1-y_true) * np.log(1 - y_pred + 1e-7)\n",
    "    term_1 = y_true * np.log(y_pred + 1e-7)\n",
    "    \n",
    "    result = -np.mean(term_0 + term_1, axis = 0)\n",
    "    \n",
    "    print('binary cross entropy:', result)\n",
    "    \n",
    "# create our data and changing the shape (forma) of an array display arr vertical\n",
    "y_true_arr = np.array([1, 1, 1])\n",
    "y_pred_arr = np.array([1, 1, 0])\n",
    "\n",
    "# call the function and send the data\n",
    "binary_cross_entropy(y_true_arr, y_pred_arr)\n",
    "\n",
    "# target value = 5.14164949"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
